{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98696e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91439269",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92165af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of input text: 1115393\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it \n"
     ]
    }
   ],
   "source": [
    "print(f'len of input text: {len(text)}')\n",
    "print(text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c82ebe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fdfd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53]\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for ch, i in stoi.items()}\n",
    "encode = lambda s: [stoi[c] for c in s]   # encoder: take a string and output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder = take a list of integers, output a string\n",
    "\n",
    "print(encode(\"hello\"))\n",
    "print(decode(encode('hi')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27dcb642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.Size([1115393])\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "# encode the entire text dataset\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.dtype, data.shape)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f070109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003853 111540\n"
     ]
    }
   ],
   "source": [
    "# training and val splits: 90% training, rest val\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(len(train_data), len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e135797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]), output is 47\n",
      "when input is tensor([18, 47]), output is 56\n",
      "when input is tensor([18, 47, 56]), output is 57\n",
      "when input is tensor([18, 47, 56, 57]), output is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]), output is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]), output is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]), output is 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]), output is 58\n"
     ]
    }
   ],
   "source": [
    "# block_size = 8  # context length or chunk size, transformer will receive chars upto the block size \n",
    "#                 # to predict next char, above block_size chunking would be required\n",
    "# x = train_data[:block_size]\n",
    "# y = train_data[1:block_size+1]\n",
    "# for t in range(block_size):\n",
    "#     context = x[:t+1]\n",
    "#     target = y[t]\n",
    "#     print(f'when input is {context}, output is {target}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb19ebe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n",
      "torch.Size([4, 8])\n",
      "outputs tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n",
      "        [43, 43, 54,  1, 47, 58,  1, 58],\n",
      "        [52, 45, 43, 50, 53,  8,  0, 26],\n",
      "        [39,  1, 46, 53, 59, 57, 43,  0]])\n",
      "torch.Size([4, 8])\n",
      "----\n",
      "input is tensor([53]), output is 59\n",
      "input is tensor([53, 59]), output is 6\n",
      "input is tensor([53, 59,  6]), output is 1\n",
      "input is tensor([53, 59,  6,  1]), output is 58\n",
      "input is tensor([53, 59,  6,  1, 58]), output is 56\n",
      "input is tensor([53, 59,  6,  1, 58, 56]), output is 47\n",
      "input is tensor([53, 59,  6,  1, 58, 56, 47]), output is 40\n",
      "input is tensor([53, 59,  6,  1, 58, 56, 47, 40]), output is 59\n",
      "input is tensor([49]), output is 43\n",
      "input is tensor([49, 43]), output is 43\n",
      "input is tensor([49, 43, 43]), output is 54\n",
      "input is tensor([49, 43, 43, 54]), output is 1\n",
      "input is tensor([49, 43, 43, 54,  1]), output is 47\n",
      "input is tensor([49, 43, 43, 54,  1, 47]), output is 58\n",
      "input is tensor([49, 43, 43, 54,  1, 47, 58]), output is 1\n",
      "input is tensor([49, 43, 43, 54,  1, 47, 58,  1]), output is 58\n",
      "input is tensor([13]), output is 52\n",
      "input is tensor([13, 52]), output is 45\n",
      "input is tensor([13, 52, 45]), output is 43\n",
      "input is tensor([13, 52, 45, 43]), output is 50\n",
      "input is tensor([13, 52, 45, 43, 50]), output is 53\n",
      "input is tensor([13, 52, 45, 43, 50, 53]), output is 8\n",
      "input is tensor([13, 52, 45, 43, 50, 53,  8]), output is 0\n",
      "input is tensor([13, 52, 45, 43, 50, 53,  8,  0]), output is 26\n",
      "input is tensor([1]), output is 39\n",
      "input is tensor([ 1, 39]), output is 1\n",
      "input is tensor([ 1, 39,  1]), output is 46\n",
      "input is tensor([ 1, 39,  1, 46]), output is 53\n",
      "input is tensor([ 1, 39,  1, 46, 53]), output is 59\n",
      "input is tensor([ 1, 39,  1, 46, 53, 59]), output is 57\n",
      "input is tensor([ 1, 39,  1, 46, 53, 59, 57]), output is 43\n",
      "input is tensor([ 1, 39,  1, 46, 53, 59, 57, 43]), output is 0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4  # how many independent sequence will we process in parallel?\n",
    "block_size = 8  # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix =  torch.randint(len(data)-block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y= torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:', xb)\n",
    "print(xb.shape)\n",
    "print('outputs', yb)\n",
    "print(yb.shape)\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size):   # batch dimension\n",
    "    for t in range(block_size) : # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f'input is {context}, output is {target}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a419893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)   # input to the transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29fcc0",
   "metadata": {},
   "source": [
    "**bigram language model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f15677c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 65])\n",
      "tensor(4.6288, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(num_embeddings=vocab_size, embedding_dim=vocab_size)\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        # idx and targets are both (B, T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx)  # ( B, T, C) arranged as batch, time, channel i.e (4, 8 65) here\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)  # https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_tokens):\n",
    "        # idx is (B, T) array of indices in current context\n",
    "        for _ in range(max_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)        \n",
    "            # focus only on the last time step\n",
    "            logits = logits[:,-1,:] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) #(B, 1)\n",
    "            # append sampled idx to running sequence\n",
    "            idx = torch.cat((idx,idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb,yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "out = decode(m.generate(idx, max_tokens=100)[0].tolist())  # m.generate output shape here is 1,101\n",
    "print(out)\n",
    "# expected loss is ln(1/65) = 4.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a5295fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pytorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(),lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d53efd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.440803050994873\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for i in range(10000):\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss  = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb563c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NICOndu t w ity merwo al LOLo bebte loolld worinero ya l aknge ond thal ttry b's mo ge ck.\n",
      "\n",
      "gh, cheetilllin trewnutud t arsu y;\n",
      "Desthap's Zimponcrdistherdrtes saure ' erpoperrposthel?\n",
      "Handis of hef thep: ct\n",
      "Ywit harfoul'st, ar izlor t ct.\n",
      "Fo, sther:\n",
      "I d tre th,-ben.\n",
      "\n",
      "HBltothedlucartee t the t,\n",
      "STEMANGENTIV:\n",
      "WDUKI HANENEThe d ndean-bros g qpl mout fok yolaime do myo asto,\n",
      "Mok h$ay t nch sle fionhou\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx= torch.zeros((1,1), dtype=torch.long),max_tokens=400)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5fc092",
   "metadata": {},
   "source": [
    "*mathematical trick in self attention*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d46a1021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "# toy example\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "256c6f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1242d8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0894"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.1808-0.3596)/2\n",
    "\n",
    "# we want to the T (here 8) tokens to communicate in a batch B i.e. we want to couple them\n",
    "# here eg. if I am a 5th token and want to communicate with the past then the simplest way is to take the avg of the preceding elements i.e. take the Channels (C) from my vector and all preceding vectors and avg them and get a new feature vector that summarizes me in the context of my history. it is an extremely weak form of communication and we have lost a lot of info\n",
    "# we want x[b,t] = mean_{i<=t} x[b,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760eef5",
   "metadata": {},
   "source": [
    "version 1: for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cba853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t, C)\n",
    "        xbow[b,t] = torch.mean(xprev,0)\n",
    "print(xbow[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f9e31",
   "metadata": {},
   "source": [
    "version 2: using mat mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b30f9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = \n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b = \n",
      "tensor([[5., 7.],\n",
      "        [2., 0.],\n",
      "        [5., 3.]])\n",
      "c = \n",
      "tensor([[5.0000, 7.0000],\n",
      "        [3.5000, 3.5000],\n",
      "        [4.0000, 3.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a/torch.sum(a, dim=1, keepdim = True)\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b\n",
    "print('a = ')\n",
    "print(a)\n",
    "print('b = ')\n",
    "print(b)\n",
    "print('c = ')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d4e695b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check it on the toy example\n",
    "wei = torch.tril(torch.ones((T, T)))\n",
    "wei = wei/wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x  # (B, T, T) @ (B, T, C) ----> (B, T, C)  (wei is T, T so batch dimension B is inserted by pytorch (hence B, T, T) and the mul happens for each batch)\n",
    "torch.allclose(xbow, xbow2, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a7868c",
   "metadata": {},
   "source": [
    "version 3: using softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01a4978a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones((T, T)))\n",
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6342af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.zeros((T,T))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0053e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ac639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T)) # initialize the affinities between all the tokens\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))  # to only use the past context and avoid the future char in the context\n",
    "wei = F.softmax(wei, dim=-1)  # normalizes\n",
    "xbow3 = wei @ x\n",
    "print(torch.allclose(xbow, xbow3,atol=1e-6))\n",
    "print(xbow3[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb1c6d",
   "metadata": {},
   "source": [
    "*Self-Attention*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a553672e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e018542f",
   "metadata": {},
   "source": [
    "We don't want the values to be uniform in wei, they should be data dependent i.e. different tokens will find different tokens more interesting. This is to be solved by self attention.\n",
    "How does it solve it??\n",
    "--> Every single token at each position emits 2 vectors - query(what am I looking for) and key(what do I contain). value (what I can communicate)\n",
    "affinities = dot product between key and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2a23506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
      "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
      "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn((B, T, C))\n",
    "\n",
    "# let's see a single head perform self attention\n",
    "head_size = 16\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)    # (B, T, 16)\n",
    "q = query(x)  # (B, T, 16)\n",
    "v = value(x)  # (B, T, 16)\n",
    "wei = q @ k.transpose(-2,-1)   # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T,T)) # initialize the affinities between all the tokens\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))  # to only use the past context and avoid the future char in the context\n",
    "wei = F.softmax(wei, dim=-1)  # normalizes\n",
    "# out = wei @ x\n",
    "out = wei @ v   # v is getting aggregated and not the raw x\n",
    "print(wei[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce179f1",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- Attention is a communication mechanism. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with tril, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides wei by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74391ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0449)\n",
      "tensor(1.0700)\n",
      "tensor(17.4690)\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B, T, head_size)  # unit gaussian\n",
    "q = torch.randn(B, T, head_size)  # unit gaussian\n",
    "wei = q @ k.transpose(-2, -1)     # this is in the order of head_size\n",
    "\n",
    "print(k.var())\n",
    "print(q.var())\n",
    "print(wei.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d38334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0966)\n",
      "tensor(0.9416)\n",
      "tensor(1.0065)\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B, T, head_size)  # unit gaussian\n",
    "q = torch.randn(B, T, head_size)  # unit gaussian\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5     # scaled so this has unit variance too \n",
    "\n",
    "print(k.var())\n",
    "print(q.var())\n",
    "print(wei.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76c2020",
   "metadata": {},
   "source": [
    "why is this important?\n",
    "\n",
    "- Wei feeds into softmax so its important that especially at initialization wei be fairly diffused\n",
    "- If wei takes on too large +ve or -ve numbers softmax will converge towards one hot vectors\n",
    "- illustrated below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f39ee8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4781f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([ 0.8000, -1.6000,  2.4000, -1.6000,  4.0000]), dim=-1)\n",
    "# it will sharpen towards whatever number will be highest (here 4.000), so we don't want these values to be too \n",
    "# exteme especially at init otherwise the softmax will be way too peaky and it would be basically be aggregating info from one single node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0eb484",
   "metadata": {},
   "source": [
    "layernorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdb0b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d: # (used to be BatchNorm1d) (layernorm is across rows instead of features/columns)\n",
    "\n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    xmean = x.mean(1, keepdim=True) # batch mean  (this used to be 0 as it was across columns/features in batchnorm)\n",
    "    xvar = x.var(1, keepdim=True) # batch variance (this used to be 0 as it was across columns/features in batchnorm)\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    return self.out\n",
    "\n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e024aeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "805b9bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
